{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94bea7ac",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 1. Import Required Libraries and Initialize SparkSession\n",
        "Import `SparkSession` from `pyspark.sql` and create a Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2159b9",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Chapter 2 Example\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9091e311",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 2. Create a DataFrame with a Range of Numbers\n",
        "Use `spark.range(1000)` to build a DataFrame of numbers from 0 to 999 and show its schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4b3508",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "myRange = spark.range(1000).toDF(\"number\")\n",
        "myRange.printSchema()\n",
        "myRange.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a31eea",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 3. Filter DataFrame for Even Numbers\n",
        "Select only even numbers using a `where` clause."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5949c832",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "divisBy2 = myRange.where(\"number % 2 = 0\")\n",
        "divisBy2.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f5dc3c",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 4. Read CSV Data into DataFrame\n",
        "Load the 2015 flight-summary CSV with inferred schema and header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94da47",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "flightData2015 = spark\n",
        "  .read\n",
        "  .option(\"inferSchema\", \"true\")\n",
        "  .option(\"header\", \"true\")\n",
        "  .csv(\"/data/flight-data/csv/2015-summary.csv\")\n",
        "flightData2015.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6de29e",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 5. Create Temporary SQL View\n",
        "Register the DataFrame as a temp view for SQL queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084f85c4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c151516b",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 6. Group and Count Using SQL and DataFrame APIs\n",
        "Count the number of flights per destination with both SQL and DataFrame methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb1ed60b",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "sqlWay = spark.sql(\"\"\"\n",
        "SELECT DEST_COUNTRY_NAME, count(1) AS cnt\n",
        "FROM flight_data_2015\n",
        "GROUP BY DEST_COUNTRY_NAME\n",
        "\"\"\")\n",
        "dataFrameWay = flightData2015.groupBy(\"DEST_COUNTRY_NAME\").count()\n",
        "sqlWay.show(5)\n",
        "dataFrameWay.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ecb573",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 7. Explain Query Execution Plans\n",
        "Use `explain()` to inspect physical plans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3730351a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"SQL plan:\")\n",
        "sqlWay.explain()\n",
        "print(\"DataFrame plan:\")\n",
        "dataFrameWay.explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1df87e66",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 8. Find Maximum Value in a Column\n",
        "Use `pyspark.sql.functions.max` to get the max of the `count` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e46fa86",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max\n",
        "flightData2015.select(max(\"count\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5cd1809",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 9. Aggregate and Sort Data Using SQL\n",
        "Sum counts by destination, sort descending, limit to top 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3029bde",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "maxSql = spark.sql(\"\"\"\n",
        "SELECT DEST_COUNTRY_NAME, sum(count) AS destination_total\n",
        "FROM flight_data_2015\n",
        "GROUP BY DEST_COUNTRY_NAME\n",
        "ORDER BY destination_total DESC\n",
        "LIMIT 5\n",
        "\"\"\")\n",
        "maxSql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf5ae4ca",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 10. Aggregate and Sort Data Using DataFrame API\n",
        "Perform the same aggregation in the DataFrame API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cb58ef",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import desc\n",
        "flightData2015\n",
        "  .groupBy(\"DEST_COUNTRY_NAME\")\n",
        "  .sum(\"count\")\n",
        "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\n",
        "  .sort(desc(\"destination_total\"))\n",
        "  .limit(5)\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32afbfb",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# 11. Explain Aggregation Query Execution Plan\n",
        "Inspect the physical plan for the DataFrame aggregation+sort query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96bb070e",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "flightData2015\n",
        "  .groupBy(\"DEST_COUNTRY_NAME\")\n",
        "  .sum(\"count\")\n",
        "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\n",
        "  .sort(desc(\"destination_total\"))\n",
        "  .limit(5)\n",
        "  .explain()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
